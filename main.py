import os
import warnings
import torch
import gc
import json
import re
import math
from PIL import Image, ImageDraw, ImageFont

# ---------------------------------------------------------
# [ì„¤ì •]
# ---------------------------------------------------------
warnings.filterwarnings("ignore")
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

INPUT_IMAGE_PATH = "test2.png"
OUTPUT_DIR = "final_menu_project"

# ëª¨ë¸ ID
OCR_MODEL_ID = "Qwen/Qwen2.5-VL-3B-Instruct"
LORA_ADAPTER_PATH = "output/qwen25_vl_ocr_lora_20eps_new"
LLM_MODEL_ID = "Qwen/Qwen2.5-7B-Instruct"
IMAGE_MODEL_ID = "SG161222/RealVisXL_V3.0_Turbo"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ---------------------------------------------------------
# [í°íŠ¸ ê²½ë¡œ]
# ---------------------------------------------------------
JP_FONT_PATH = "C:/Users/JONGWOONG/Downloads/SourceHanSansJP/SourceHanSansJP-VF.otf"
KR_FONT_PATH = "C:/Windows/Fonts/malgun.ttf"

from transformers import AutoProcessor, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig

try:
    from transformers import Qwen2_5_VLForConditionalGeneration
except Exception:
    try:
        from transformers.models.qwen2_5_vl.modeling_qwen2_5_vl import (
            Qwen2_5_VLForConditionalGeneration,
        )
    except Exception as e:
        raise ImportError(
            "Qwen2.5-VL ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            "`transformers`ë¥¼ Qwen2.5-VL ì§€ì› ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì„¸ìš”."
        ) from e

from qwen_vl_utils import process_vision_info
from peft import PeftModel
from diffusers import AutoPipelineForText2Image, DPMSolverMultistepScheduler


# ==========================================
# ë©”ëª¨ë¦¬ ì²­ì†Œ
# ==========================================
def flush_memory():
    gc.collect()
    torch.cuda.empty_cache()


# ==========================================
# ìœ í‹¸ í•¨ìˆ˜
# ==========================================
def _parse_menu_line(line: str):
    """OCR ë¼ì¸ì—ì„œ ì´ë¦„ê³¼ ê°€ê²© ì¶”ì¶œ"""
    raw = (line or "").strip()
    if not raw:
        return {"name": "", "price": None}

    if "|" in raw:
        left, right = raw.split("|", 1)
        name = left.strip()
        price_str = re.sub(r"[^\d]", "", right)
        price = int(price_str) if price_str else None
        return {"name": name, "price": price}

    # ê°€ê²©ì´ ì„ì—¬ ìˆëŠ” ê²½ìš°
    price_match = re.search(r"(?:[Â¥ï¿¥]\s*)?(\d{2,4})\s*(?:å††)?", raw)
    if price_match:
        price_str = price_match.group(1)
        price = int(price_str) if price_str else None
        name = re.sub(r"[Â¥ï¿¥]?\s*\d{2,4}\s*å††?", "", raw).strip()
        return {"name": name, "price": price}

    return {"name": raw, "price": None}


# ==========================================
# í°íŠ¸ ë¡œë”
# ==========================================
def get_jp_font(size):
    """ì¼ë³¸ì–´ ì „ìš© í°íŠ¸"""
    try:
        return ImageFont.truetype(JP_FONT_PATH, size)
    except Exception as e:
        print(f"âš ï¸ JP í°íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return ImageFont.load_default()


def get_kr_font(size):
    """í•œêµ­ì–´ ì „ìš© í°íŠ¸"""
    try:
        return ImageFont.truetype(KR_FONT_PATH, size)
    except Exception as e:
        print(f"âš ï¸ KR í°íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return ImageFont.load_default()


# ==========================================
# ë©”ë‰´ í•­ëª© ì¶”ì¶œ
# ==========================================
def extract_menu_items(raw_text):
    """OCR í…ìŠ¤íŠ¸ì—ì„œ ë©”ë‰´ í•­ëª©ë§Œ ì¶”ì¶œ"""
    price_pattern = r'([ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯a-zA-Z\s]+?)\s*[Â¥ï¿¥]?\s*(\d{2,4})\s*[å††]?'
    matches = re.finditer(price_pattern, raw_text)

    menu_items = []
    seen = set()

    for match in matches:
        name = match.group(1).strip()
        price = match.group(2)

        skip_patterns = [
            r'^\d+',
            r'[!ï¼ï¼Ÿ?]',
            r'(ä¸€æŠ¼|è¿·ã£ãŸ|ã‚¢ãƒŠã‚¿|äººæ°—|ã‚ªãƒªã‚¸ãƒŠãƒ«|é™å®š|ãŠã™ã™ã‚|æ–°ç™»å ´)',
            r'^[a-zA-Z\s]{1,2}$',
            r'(ã§ã™|ã¾ã™|ã‹ã‚‰|ã€|ã€‚)',
        ]

        should_skip = any(re.search(pattern, name) for pattern in skip_patterns)

        if should_skip or len(name) < 2 or len(name) > 30:
            continue

        if not re.search(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]', name):
            continue

        key = name + price
        if key in seen:
            continue
        seen.add(key)

        menu_items.append(f"{name} | Â¥{price}")

    # ê°€ê²© ì—†ëŠ” ë©”ë‰´
    lines = raw_text.split('\n')
    for line in lines:
        line = line.strip()

        if any(line in item for item in menu_items):
            continue

        if re.search(r'[Â¥ï¿¥]\s*\d+|\d{2,4}\s*å††', line):
            continue

        if not line or len(line) < 2 or len(line) > 25:
            continue

        if not re.search(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]', line):
            continue

        skip_patterns = [
            r'[!ï¼ï¼Ÿ?]',
            r'(ä¸€æŠ¼|è¿·ã£ãŸ|ã‚¢ãƒŠã‚¿|äººæ°—|ã‚ªãƒªã‚¸ãƒŠãƒ«|é™å®š|ãŠã™ã™ã‚)',
            r'(ã§ã™|ã¾ã™|ã‹ã‚‰|ã€|ã€‚)',
            r'^\d{4}',
        ]

        should_skip = any(re.search(pattern, line) for pattern in skip_patterns)

        if not should_skip and line not in seen:
            menu_items.append(line)
            seen.add(line)

    return menu_items


# ==========================================
# [Step 1] OCR: ì†ê¸€ì”¨ ì½ê¸°
# ==========================================
def run_pure_ocr(image_path):
    print("\nğŸ‘€ [Step 1] OCR: ì†ê¸€ì”¨ ì½ê¸°...")
    try:
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            OCR_MODEL_ID, torch_dtype=torch.bfloat16, device_map="cuda"
        )
        model = PeftModel.from_pretrained(model, LORA_ADAPTER_PATH)
        processor = AutoProcessor.from_pretrained(
            OCR_MODEL_ID,
            min_pixels=256 * 28 * 28,
            max_pixels=1280 * 28 * 28
        )

        prompt = "Read all text in this image."

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": prompt}
                ]
            }
        ]

        text_input = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = processor(
            text=[text_input],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt"
        ).to(model.device)

        with torch.no_grad():
            generated_ids = model.generate(**inputs, max_new_tokens=1200)

        generated_ids_trimmed = [
            out_ids[len(in_ids):]
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        raw_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]

        print(f"   ğŸ“ [OCR ì›ë³¸]\n{raw_text[:300]}...\n")

        menu_items = extract_menu_items(raw_text)
        formatted_text = '\n'.join(menu_items)

        print(f"   âœ… ë©”ë‰´ ì¶”ì¶œ ({len(menu_items)}ê°œ)\n{formatted_text}\n")

        del model, processor
        flush_memory()
        return formatted_text

    except Exception as e:
        print(f"âŒ OCR ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


# ==========================================
# [Step 2] LLM: ë²ˆì—­ ë° ì„¤ëª… ìƒì„± (1ê°œì”©)
# ==========================================
def run_llm_logic(raw_text):
    print("\nğŸ§  [Step 2] LLM: ë©”ë‰´ ì •ë³´ ìƒì„± ì¤‘...")

    menu_lines = [line for line in raw_text.strip().split('\n') if line.strip()]
    all_menu_data = []

    try:
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16
        )

        tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID)
        model = AutoModelForCausalLM.from_pretrained(
            LLM_MODEL_ID,
            quantization_config=bnb_config,
            device_map="cuda"
        )

        if tokenizer.pad_token_id is None:
            tokenizer.pad_token_id = tokenizer.eos_token_id

        # âœ¨ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """You are a Japaneseâ†’Korean menu translator.
Output ONLY valid JSON. name_ko and description MUST be in Korean (í•œê¸€)."""

        # âœ¨ ìš©ì–´ì§‘
        glossary = """
[Japanese Food Glossary]
ã‚¤ã‚¯ãƒ©=ì´ì¿ ë¼(ì—°ì–´ì•Œ) | ãŠé€ ã‚Š=ì˜¤ì¸ ì¿ ë¦¬(íšŒ) | ä¸¼=ë™(ë®ë°¥)
ç´è±†=ë‚«í† (ì²­êµ­ì¥) | æ¢…å¹²ã—=ìš°ë©”ë³´ì‹œ(ë§¤ì‹¤ì¥ì•„ì°Œ) | å†·å¥´=íˆì•¼ì–ì½”(ëƒ‰ë‘ë¶€)
ãªã‚ã‚ã†=ë‚˜ë©”ë¡œ(ìƒì„ íšŒë¬´ì¹¨) | æµ·é®®=ì¹´ì´ì„¼(í•´ì‚°ë¬¼) | å®šé£Ÿ=í…Œì´ì‡¼ì¿ (ì •ì‹)
ã‚«ãƒ=ì¹´ë§ˆ(í„±ì‚´) | é®®é­š=ì„¼êµ(ì‹ ì„ í•œìƒì„ ) | ç„¼ã=ì•¼í‚¤(êµ¬ì´)
ç‰å­=íƒ€ë§ˆê³ (ê³„ë€) | åµ=íƒ€ë§ˆê³ (ì•Œ) | ç…®åµ=ë‹ˆíƒ€ë§ˆê³ (ë°˜ìˆ™ë€)
ã‚µãƒ=ì‚¬ë°”(ê³ ë“±ì–´) | æ˜å¤ª=ë©˜íƒ€ì´(ëª…ë€) | ã‚«ãƒ³ãƒ‘ãƒ=ì¹¸íŒŒì¹˜(ë°©ì–´)
ã‚­ãƒ ãƒ=ê¹€ì¹˜ | ã”ã¯ã‚“=ê³ í•­(ë°¥) | ãŠã‹ã‚ã‚Š=ì˜¤ì¹´ì™€ë¦¬(ë¦¬í•„)
ã®ã‚Š=ë…¸ë¦¬(ê¹€) | èƒ¡éº»=ê³ ë§ˆ(ì°¸ê¹¨) | è¿½åŠ =ì¸ ì´ì¹´(ì¶”ê°€)
ä¸€å“=ì´í•€(í•œê·¸ë¦‡) | å¢—ã—=ë§ˆì‹œ(ì¶”ê°€) | ãƒã‚¿=ë„¤íƒ€(ì¬ë£Œ)
ãƒˆãƒ­=í† ë¡œ(ì°¸ì¹˜ë±ƒì‚´) | ã‚µãƒ¼ãƒ¢ãƒ³=ì‚¬ëª¬(ì—°ì–´) | ã¾ãã‚=ë§ˆêµ¬ë¡œ(ì°¸ì¹˜)
ã†ã«=ìš°ë‹ˆ(ì„±ê²Œ) | ãˆã³=ì—ë¹„(ìƒˆìš°) | ãŸã“=íƒ€ì½”(ë¬¸ì–´)
ã„ã‹=ì´ì¹´(ì˜¤ì§•ì–´) | ã»ãŸã¦=í˜¸íƒ€í…Œ(ê°€ë¦¬ë¹„) | åˆºèº«=ì‚¬ì‹œë¯¸(íšŒ)
ç”Ÿ=ë‚˜ë§ˆ(ìƒ) | æšã’=ì•„ê²Œ(íŠ€ê¹€) | ç…®=ë‹ˆ(ì¡°ë¦¼)
ç‚’ã‚=ì´íƒ€ë©”(ë³¶ìŒ) | è’¸ã—=ë¬´ì‹œ(ì°œ) | æè±†=ì—ë‹¤ë§ˆë©”(í’‹ì½©)
"""

        total = len(menu_lines)

        # âœ¨ 1ê°œì”© ì²˜ë¦¬
        for idx, line in enumerate(menu_lines):
            print(f"   âš™ï¸ [{idx + 1}/{total}] ì²˜ë¦¬ ì¤‘: {line[:40]}...")

            parsed = _parse_menu_line(line)
            name = parsed["name"]
            price = parsed["price"]

            if not name:
                print(f"      âš ï¸ ê±´ë„ˆëœ€ (ì´ë¦„ ì—†ìŒ)")
                continue

            user_prompt = f"""
{glossary}

[Menu Item]
Name: "{name}"
Price: {price if price else "null"}

[Task]
Translate to Korean using the glossary above.
Output ONE JSON object:

{{
  "name": "{name}",
  "price": {price if price else "null"},
  "name_ko": "accurate Korean translation",
  "description": "Korean description (1-2 sentences)",
  "category": "meat|seafood|vegetable|drink|dessert|food",
  "t2i_prompt": "English food photography prompt"
}}

CRITICAL:
- name_ko MUST be in Korean (í•œê¸€)
- description MUST be in Korean (í•œê¸€)
- Use glossary for accurate translation
- Output ONLY JSON, no markdown, no commentary

Translate:
"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            text = tokenizer.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

            with torch.no_grad():
                generated_ids = model.generate(
                    **model_inputs,
                    max_new_tokens=2000,
                    temperature=0.1,
                    do_sample=False,
                    pad_token_id=tokenizer.pad_token_id,
                    eos_token_id=tokenizer.eos_token_id,
                )

            generated_ids = [
                output_ids[len(input_ids):]
                for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            output_text = tokenizer.batch_decode(
                generated_ids, skip_special_tokens=True
            )[0]

            # âœ¨ JSON íŒŒì‹± (ì‹¤íŒ¨í•˜ë©´ ìŠ¤í‚µ)
            try:
                # ì½”ë“œíœìŠ¤ ì œê±°
                clean = re.sub(r'```json|```', '', output_text).strip()

                # ì²« { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€
                start = clean.find('{')
                end = clean.rfind('}')

                if start == -1 or end == -1:
                    raise ValueError("No JSON found")

                json_str = clean[start:end + 1]
                item = json.loads(json_str)

                # ì›ë³¸ ë³´ì¡´
                item["name"] = name
                item["price"] = price

                all_menu_data.append(item)
                print(f"      âœ… {name} â†’ {item.get('name_ko', '?')}")

            except Exception as e:
                print(f"      âŒ íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}")
                # Fallback: ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€
                all_menu_data.append({
                    "name": name,
                    "price": price,
                    "name_ko": name,
                    "description": "ë©”ë‰´ ì„¤ëª…",
                    "category": "food",
                    "t2i_prompt": "Japanese food on plate"
                })
                print(f"      âš ï¸ ê¸°ë³¸ê°’ ì‚¬ìš©")
                continue

        del model, tokenizer
        flush_memory()

        print(f"\n   âœ… ì´ {len(all_menu_data)}ê°œ ì™„ë£Œ (ì‹¤íŒ¨: {total - len(all_menu_data)}ê°œ)\n")

        if all_menu_data:
            print("   ğŸ“‹ ìƒì„±ëœ ë©”ë‰´:")
            for item in all_menu_data[:10]:
                print(f"      {item.get('name', '?')} â†’ {item.get('name_ko', '?')}")
            if len(all_menu_data) > 10:
                print(f"      ... ì™¸ {len(all_menu_data) - 10}ê°œ")
        print()

        return all_menu_data


    except Exception as e:

        print(f"      âŒ íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}")

        # âœ¨ ì¹´í…Œê³ ë¦¬ ì¶”ì¸¡

        category = 'food'

        if re.search(r'(è‚‰|ç‰›|è±š|é¶|ãƒã‚­ãƒ³)', name):

            category = 'meat'

        elif re.search(r'(é­š|åˆºèº«|å¯¿å¸|æµ·é®®|ã‚¤ã‚«|ã‚¿ã‚³|ã‚¨ãƒ“)', name):

            category = 'seafood'

        elif re.search(r'(é‡èœ|ã‚µãƒ©ãƒ€|ã‚­ãƒ£ãƒ™ãƒ„)', name):

            category = 'vegetable'

        elif re.search(r'(ãƒ“ãƒ¼ãƒ«|é…’|ãƒ‰ãƒªãƒ³ã‚¯|ã‚¸ãƒ¥ãƒ¼ã‚¹)', name):

            category = 'drink'

        elif re.search(r'(ãƒ‡ã‚¶ãƒ¼ãƒˆ|ã‚±ãƒ¼ã‚­|ã‚¢ã‚¤ã‚¹)', name):

            category = 'dessert'

        all_menu_data.append({

            "name": name,

            "price": price,

            "name_ko": name,

            "description": "ë©”ë‰´ ì„¤ëª…",

            "category": category,

            "t2i_prompt": f"Japanese {category} dish on plate, izakaya style"

        })

        print(f"      âš ï¸ ê¸°ë³¸ê°’ ì‚¬ìš© (category: {category})")


# ==========================================
# [Step 3] ì´ë¯¸ì§€ ìƒì„±
# ==========================================
def run_image_gen(menu_data):
    print("\nğŸ¨ [Step 3] ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    if not menu_data:
        return []

    try:
        pipe = AutoPipelineForText2Image.from_pretrained(
            IMAGE_MODEL_ID,
            torch_dtype=torch.float16,
            variant="fp16"
        ).to("cuda")
        pipe.scheduler = DPMSolverMultistepScheduler.from_config(
            pipe.scheduler.config, use_karras_sigmas=True
        )
        pipe.set_progress_bar_config(disable=True)
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return menu_data

    for idx, item in enumerate(menu_data):
        name = item.get('name', 'Unknown')
        name_ko = item.get('name_ko', '')
        base_prompt = item.get('t2i_prompt', 'delicious food on plate')

        full_prompt = (
            f"{base_prompt}, "
            "(masterpiece:1.3), (best quality:1.2), (photorealistic:1.4), "
            "professional food photography, 8k uhd, sharp focus, "
            "appetizing, detailed texture, shallow depth of field"
        )

        negative_prompt = (
            "text, watermark, logo, blurry, cartoon, anime, drawing, "
            "illustration, ugly, deformed, low quality, worst quality"
        )

        print(f"   ğŸ± [{idx + 1}/{len(menu_data)}] {name} ({name_ko})")

        try:
            image = pipe(
                prompt=full_prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=8,
                guidance_scale=2.5,
                height=512,
                width=512
            ).images[0]

            safe_name = re.sub(r'[<>:"/\\|?*]', '_', name[:30])
            path = os.path.join(OUTPUT_DIR, f"menu_{idx:02d}_{safe_name}.png")
            image.save(path)
            item['image_path'] = path
            print(f"      âœ… ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            print(f"      âš ï¸ ìƒì„± ì‹¤íŒ¨: {str(e)[:60]}")

            placeholder = Image.new('RGB', (512, 512), (50, 50, 50))
            draw_ph = ImageDraw.Draw(placeholder)

            font = get_kr_font(24)
            text = f"{name_ko}\n\nì´ë¯¸ì§€ ìƒì„±\nì‹¤íŒ¨"
            draw_ph.text(
                (256, 256),
                text,
                fill="white",
                anchor="mm",
                font=font,
                align="center"
            )

            safe_name = re.sub(r'[<>:"/\\|?*]', '_', name[:30])
            path = os.path.join(OUTPUT_DIR, f"menu_{idx:02d}_{safe_name}.png")
            placeholder.save(path)
            item['image_path'] = path

    del pipe
    flush_memory()
    return menu_data


# ==========================================
# [Step 4] ìµœì¢… ë©”ë‰´íŒ ì¡°ë¦½
# ==========================================
def create_board(menu_items):
    print("\nğŸ± [Step 4] ìµœì¢… ë©”ë‰´íŒ ìƒì„± ì¤‘...")
    if not menu_items:
        print("âŒ ë©”ë‰´ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
        return

    cols = 3
    rows = math.ceil(len(menu_items) / cols)
    img_size = 420
    card_width = img_size + 40
    card_height = img_size + 200

    board_width = cols * card_width + 80
    board_height = rows * card_height + 140

    board = Image.new("RGB", (board_width, board_height), (20, 20, 20))
    draw = ImageDraw.Draw(board)

    # í°íŠ¸ ë¡œë“œ
    title_font_jp = get_jp_font(48)
    font_name_jp = get_jp_font(24)
    font_ko = get_kr_font(22)
    font_desc_kr = get_kr_font(16)
    font_price_kr = get_kr_font(26)

    # íƒ€ì´í‹€
    draw.text(
        (board_width // 2, 50),
        "ğŸ¶ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ ğŸ¶",
        fill=(255, 255, 255),
        anchor="mm",
        font=title_font_jp
    )

    for idx, item in enumerate(menu_items):
        col = idx % cols
        row = idx // cols

        x = 40 + col * card_width
        y = 100 + row * card_height

        # ê·¸ë¦¼ì
        shadow_offset = 4
        draw.rectangle(
            [x + shadow_offset, y + shadow_offset,
             x + card_width - 20 + shadow_offset, y + card_height - 20 + shadow_offset],
            fill=(10, 10, 10)
        )

        # ì¹´ë“œ ë°°ê²½
        draw.rectangle(
            [x, y, x + card_width - 20, y + card_height - 20],
            fill=(40, 40, 40),
            outline=(100, 100, 100),
            width=2
        )

        # ì´ë¯¸ì§€
        img_x, img_y = x + 10, y + 10
        if 'image_path' in item and os.path.exists(item['image_path']):
            try:
                menu_img = Image.open(item['image_path']).resize((img_size, img_size))
                board.paste(menu_img, (img_x, img_y))
            except:
                draw.rectangle(
                    [img_x, img_y, img_x + img_size, img_y + img_size],
                    outline=(80, 80, 80),
                    width=2
                )
        else:
            draw.rectangle(
                [img_x, img_y, img_x + img_size, img_y + img_size],
                outline=(80, 80, 80),
                width=2
            )

        # í…ìŠ¤íŠ¸
        text_y = img_y + img_size + 20
        text_x = img_x + 10

        # ì¼ë³¸ì–´ ì´ë¦„
        name = item.get('name', 'Unknown')
        if len(name) > 25:
            name = name[:23] + "..."
        draw.text(
            (text_x, text_y),
            name,
            fill=(255, 255, 255),
            font=font_name_jp
        )

        # í•œêµ­ì–´ ë²ˆì—­
        name_ko = item.get('name_ko', '')
        if len(name_ko) > 28:
            name_ko = name_ko[:26] + "..."
        draw.text(
            (text_x, text_y + 35),
            name_ko,
            fill=(255, 215, 0),
            font=font_ko
        )

        # ì„¤ëª…
        desc = item.get('description', '')
        if len(desc) > 35:
            if ' ' in desc[:35]:
                desc = desc[:35].rsplit(' ', 1)[0] + "..."
            else:
                desc = desc[:33] + "..."
        draw.text(
            (text_x, text_y + 70),
            desc,
            fill=(190, 190, 190),
            font=font_desc_kr
        )

        # ê°€ê²©
        price = item.get('price')
        if price is not None:
            draw.text(
                (img_x + img_size - 10, text_y + 110),
                f"Â¥{int(price)}",
                fill=(100, 255, 100),
                font=font_price_kr,
                anchor="ra"
            )

    final_path = os.path.join(OUTPUT_DIR, "FINAL_MENU_BOARD.png")
    board.save(final_path, quality=95)

    print(f"\nâœ… ì™„ë£Œ!")
    print(f"   ğŸ“ ì €ì¥ ê²½ë¡œ: {final_path}")
    print(f"   ğŸ“Š ì´ {len(menu_items)}ê°œ ë©”ë‰´")


# ==========================================
# [ë©”ì¸ ì‹¤í–‰]
# ==========================================
if __name__ == "__main__":
    flush_memory()
    print("=" * 60)
    print("ğŸ¶ ë©”ë‰´íŒ ìƒì„± ì‹œìŠ¤í…œ (Simple Version)")
    print("=" * 60)

    raw_text = run_pure_ocr(INPUT_IMAGE_PATH)

    if raw_text:
        menu_data = run_llm_logic(raw_text)

        if menu_data:
            menu_data = run_image_gen(menu_data)
            create_board(menu_data)
        else:
            print("\nâŒ ë©”ë‰´ ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
    else:
        print("\nâŒ OCR ì‹¤íŒ¨")

    print("\n" + "=" * 60)